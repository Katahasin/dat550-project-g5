{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for classsifying using a Artificial Neural Network (NN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is excpecting the data to be numeric. A method of ensuring this to first use Pre_Processing_USE-4.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cells are executed in the order in which they appear in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard # Uncomment this line to use tensorboard\n",
    "\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import numerical feature and label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X = pd.read_csv('X_numeric.csv', sep=',', header=None)\n",
    "y = pd.read_csv('y_numeric.csv', sep=',', header=None)\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.480624e+10</td>\n",
       "      <td>1.480624e+10</td>\n",
       "      <td>1.480624e+10</td>\n",
       "      <td>16.178530</td>\n",
       "      <td>12.164207</td>\n",
       "      <td>1.753315</td>\n",
       "      <td>-5.300097</td>\n",
       "      <td>1.016841</td>\n",
       "      <td>8.118670</td>\n",
       "      <td>6.819417</td>\n",
       "      <td>...</td>\n",
       "      <td>11.372132</td>\n",
       "      <td>7.036551</td>\n",
       "      <td>-2.552680</td>\n",
       "      <td>-54.153320</td>\n",
       "      <td>32.803783</td>\n",
       "      <td>16.710754</td>\n",
       "      <td>-24.062065</td>\n",
       "      <td>6.590991</td>\n",
       "      <td>-0.729850</td>\n",
       "      <td>6.655100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.475470e+11</td>\n",
       "      <td>4.475470e+11</td>\n",
       "      <td>4.475470e+11</td>\n",
       "      <td>20.004223</td>\n",
       "      <td>11.334753</td>\n",
       "      <td>-2.820019</td>\n",
       "      <td>-7.355494</td>\n",
       "      <td>-1.181901</td>\n",
       "      <td>6.805092</td>\n",
       "      <td>0.625156</td>\n",
       "      <td>...</td>\n",
       "      <td>21.825056</td>\n",
       "      <td>13.261285</td>\n",
       "      <td>-17.120144</td>\n",
       "      <td>4.034127</td>\n",
       "      <td>-10.328978</td>\n",
       "      <td>-12.635922</td>\n",
       "      <td>-22.477568</td>\n",
       "      <td>3.983698</td>\n",
       "      <td>-0.710531</td>\n",
       "      <td>4.778454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.536947e+09</td>\n",
       "      <td>4.536947e+09</td>\n",
       "      <td>4.536947e+09</td>\n",
       "      <td>19.789394</td>\n",
       "      <td>11.128526</td>\n",
       "      <td>-5.510750</td>\n",
       "      <td>-8.971125</td>\n",
       "      <td>4.214148</td>\n",
       "      <td>-21.717592</td>\n",
       "      <td>6.829502</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.366057</td>\n",
       "      <td>6.523605</td>\n",
       "      <td>-5.956306</td>\n",
       "      <td>8.049953</td>\n",
       "      <td>-8.431773</td>\n",
       "      <td>-1.328702</td>\n",
       "      <td>19.821604</td>\n",
       "      <td>2.230384</td>\n",
       "      <td>-2.804008</td>\n",
       "      <td>4.660541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.897625e+10</td>\n",
       "      <td>3.897625e+10</td>\n",
       "      <td>3.897625e+10</td>\n",
       "      <td>19.559141</td>\n",
       "      <td>11.153430</td>\n",
       "      <td>-7.129503</td>\n",
       "      <td>14.209820</td>\n",
       "      <td>4.214219</td>\n",
       "      <td>-21.717434</td>\n",
       "      <td>-10.894494</td>\n",
       "      <td>...</td>\n",
       "      <td>12.437857</td>\n",
       "      <td>30.452587</td>\n",
       "      <td>15.085895</td>\n",
       "      <td>-17.211315</td>\n",
       "      <td>-9.998230</td>\n",
       "      <td>-9.034165</td>\n",
       "      <td>21.270443</td>\n",
       "      <td>-3.827162</td>\n",
       "      <td>-2.322451</td>\n",
       "      <td>4.214811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.425274e+10</td>\n",
       "      <td>1.425274e+10</td>\n",
       "      <td>1.425274e+10</td>\n",
       "      <td>19.156839</td>\n",
       "      <td>11.093230</td>\n",
       "      <td>-4.028421</td>\n",
       "      <td>3.910608</td>\n",
       "      <td>0.271392</td>\n",
       "      <td>7.674269</td>\n",
       "      <td>3.828856</td>\n",
       "      <td>...</td>\n",
       "      <td>12.387394</td>\n",
       "      <td>15.096603</td>\n",
       "      <td>4.221771</td>\n",
       "      <td>-12.505415</td>\n",
       "      <td>6.967276</td>\n",
       "      <td>-8.013271</td>\n",
       "      <td>13.346799</td>\n",
       "      <td>3.252636</td>\n",
       "      <td>1.021878</td>\n",
       "      <td>7.317034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2          3          4         5   \\\n",
       "0  1.480624e+10  1.480624e+10  1.480624e+10  16.178530  12.164207  1.753315   \n",
       "1  4.475470e+11  4.475470e+11  4.475470e+11  20.004223  11.334753 -2.820019   \n",
       "2  4.536947e+09  4.536947e+09  4.536947e+09  19.789394  11.128526 -5.510750   \n",
       "3  3.897625e+10  3.897625e+10  3.897625e+10  19.559141  11.153430 -7.129503   \n",
       "4  1.425274e+10  1.425274e+10  1.425274e+10  19.156839  11.093230 -4.028421   \n",
       "\n",
       "          6         7          8          9   ...         61         62  \\\n",
       "0  -5.300097  1.016841   8.118670   6.819417  ...  11.372132   7.036551   \n",
       "1  -7.355494 -1.181901   6.805092   0.625156  ...  21.825056  13.261285   \n",
       "2  -8.971125  4.214148 -21.717592   6.829502  ...  -4.366057   6.523605   \n",
       "3  14.209820  4.214219 -21.717434 -10.894494  ...  12.437857  30.452587   \n",
       "4   3.910608  0.271392   7.674269   3.828856  ...  12.387394  15.096603   \n",
       "\n",
       "          63         64         65         66         67        68        69  \\\n",
       "0  -2.552680 -54.153320  32.803783  16.710754 -24.062065  6.590991 -0.729850   \n",
       "1 -17.120144   4.034127 -10.328978 -12.635922 -22.477568  3.983698 -0.710531   \n",
       "2  -5.956306   8.049953  -8.431773  -1.328702  19.821604  2.230384 -2.804008   \n",
       "3  15.085895 -17.211315  -9.998230  -9.034165  21.270443 -3.827162 -2.322451   \n",
       "4   4.221771 -12.505415   6.967276  -8.013271  13.346799  3.252636  1.021878   \n",
       "\n",
       "         70  \n",
       "0  6.655100  \n",
       "1  4.778454  \n",
       "2  4.660541  \n",
       "3  4.214811  \n",
       "4  7.317034  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data in case the first row is the index \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the labels in case the first row is the index\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the index has been added to the first column, run this cell \n",
    "X=X.iloc[:,1:]\n",
    "y=y.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to train and test sets. Save them as np.array and make sure they are float. Perform scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to array and make sure dtype is float or else the scaling might not work.\n",
    "X_train=np.asarray(X_train).astype(np.float_)\n",
    "X_test=np.asarray(X_test).astype(np.float_)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.float_)\n",
    "y_test=np.asarray(y_test).astype(np.float_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design the model using Keras Tuner, find optimal learning rate and epochs. Train the model and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17c5d071ca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model using Keras Tuner.\n",
    "def model_builder(hp):\n",
    "  model = Sequential()\n",
    "\n",
    "  # Tune the number of units up to five Dense layers\n",
    "  # Choose an optimal value of units between 10-100\n",
    "  for i in range(hp.Int('layers', 0, 5)):\n",
    "    model.add(Dense(units=hp.Int('units_' + str(i), 10, 100, step=10), activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid', 'tanh'])))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "model_builder(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\hyperpartisan_news_classifier_statuses6\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\hyperpartisan_news_classifier_statuses6\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Create the tuner\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     hyperband_iterations=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='hyperpartisan_news_classifier_statuses6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the tuner if validation loss does not improve for 5 consecutive epochs\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run the tuner\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\hyperpartisan_news_classifier_statuses6\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000017C5D1478B0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "learning_rate: 0.0001\n",
      "units_0: 80\n",
      "act_0: tanh\n",
      "units_1: 80\n",
      "act_1: relu\n",
      "units_2: 80\n",
      "act_2: tanh\n",
      "units_3: 40\n",
      "act_3: relu\n",
      "units_4: 80\n",
      "act_4: relu\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.7931249737739563\n"
     ]
    }
   ],
   "source": [
    "# Get the summary of the best model\n",
    "tuner.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 22ms/step - loss: 0.5862 - accuracy: 0.7214 - val_loss: 0.5522 - val_accuracy: 0.7619\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5667 - accuracy: 0.7357 - val_loss: 0.5434 - val_accuracy: 0.7429\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7357 - val_loss: 0.5400 - val_accuracy: 0.7429\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7429 - val_loss: 0.5393 - val_accuracy: 0.7429\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7381 - val_loss: 0.5409 - val_accuracy: 0.7333\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7429 - val_loss: 0.5398 - val_accuracy: 0.7333\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7429 - val_loss: 0.5409 - val_accuracy: 0.7333\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7429 - val_loss: 0.5436 - val_accuracy: 0.7333\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7429 - val_loss: 0.5454 - val_accuracy: 0.7333\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7476 - val_loss: 0.5469 - val_accuracy: 0.7333\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7500 - val_loss: 0.5452 - val_accuracy: 0.7429\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7500 - val_loss: 0.5470 - val_accuracy: 0.7429\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7524 - val_loss: 0.5465 - val_accuracy: 0.7429\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7548 - val_loss: 0.5456 - val_accuracy: 0.7524\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7667 - val_loss: 0.5460 - val_accuracy: 0.7524\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7690 - val_loss: 0.5471 - val_accuracy: 0.7429\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7690 - val_loss: 0.5498 - val_accuracy: 0.7524\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7690 - val_loss: 0.5505 - val_accuracy: 0.7524\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7690 - val_loss: 0.5506 - val_accuracy: 0.7524\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7690 - val_loss: 0.5524 - val_accuracy: 0.7714\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7738 - val_loss: 0.5569 - val_accuracy: 0.7524\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7762 - val_loss: 0.5568 - val_accuracy: 0.7619\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7786 - val_loss: 0.5603 - val_accuracy: 0.7619\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7786 - val_loss: 0.5675 - val_accuracy: 0.7429\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7881 - val_loss: 0.5668 - val_accuracy: 0.7429\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7929 - val_loss: 0.5687 - val_accuracy: 0.7429\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7857 - val_loss: 0.5687 - val_accuracy: 0.7429\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7929 - val_loss: 0.5706 - val_accuracy: 0.7429\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8000 - val_loss: 0.5725 - val_accuracy: 0.7238\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8000 - val_loss: 0.5733 - val_accuracy: 0.7238\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8000 - val_loss: 0.5772 - val_accuracy: 0.7238\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8000 - val_loss: 0.5779 - val_accuracy: 0.7238\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8024 - val_loss: 0.5816 - val_accuracy: 0.7429\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8071 - val_loss: 0.5859 - val_accuracy: 0.7333\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8071 - val_loss: 0.5881 - val_accuracy: 0.7333\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8167 - val_loss: 0.5911 - val_accuracy: 0.7238\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8262 - val_loss: 0.5953 - val_accuracy: 0.7333\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8238 - val_loss: 0.5934 - val_accuracy: 0.7238\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8214 - val_loss: 0.5963 - val_accuracy: 0.7238\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8310 - val_loss: 0.6029 - val_accuracy: 0.7238\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8333 - val_loss: 0.6031 - val_accuracy: 0.7333\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8381 - val_loss: 0.6038 - val_accuracy: 0.7238\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8476 - val_loss: 0.6083 - val_accuracy: 0.7333\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8548 - val_loss: 0.6104 - val_accuracy: 0.7238\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3486 - accuracy: 0.8524 - val_loss: 0.6112 - val_accuracy: 0.7238\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8548 - val_loss: 0.6110 - val_accuracy: 0.7333\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8595 - val_loss: 0.6137 - val_accuracy: 0.7143\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8619 - val_loss: 0.6172 - val_accuracy: 0.7143\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8667 - val_loss: 0.6251 - val_accuracy: 0.7048\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8667 - val_loss: 0.6248 - val_accuracy: 0.7048\n",
      "Best epoch: 20\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs to check the optimal number of epochs,\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 0.6519 - accuracy: 0.6095 - val_loss: 0.6077 - val_accuracy: 0.7238\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.6105 - accuracy: 0.6905 - val_loss: 0.5911 - val_accuracy: 0.7143\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.5845 - accuracy: 0.7333 - val_loss: 0.5843 - val_accuracy: 0.7429\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5680 - accuracy: 0.7357 - val_loss: 0.5843 - val_accuracy: 0.7429\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5579 - accuracy: 0.7381 - val_loss: 0.5856 - val_accuracy: 0.7429\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5489 - accuracy: 0.7381 - val_loss: 0.5867 - val_accuracy: 0.7429\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.5425 - accuracy: 0.7381 - val_loss: 0.5890 - val_accuracy: 0.7429\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5354 - accuracy: 0.7405 - val_loss: 0.5895 - val_accuracy: 0.7429\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.5297 - accuracy: 0.7429 - val_loss: 0.5896 - val_accuracy: 0.7429\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.5235 - accuracy: 0.7429 - val_loss: 0.5906 - val_accuracy: 0.7429\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.5177 - accuracy: 0.7429 - val_loss: 0.5914 - val_accuracy: 0.7429\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.5129 - accuracy: 0.7429 - val_loss: 0.5915 - val_accuracy: 0.7429\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.5078 - accuracy: 0.7429 - val_loss: 0.5936 - val_accuracy: 0.7429\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.5026 - accuracy: 0.7452 - val_loss: 0.5952 - val_accuracy: 0.7429\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.4972 - accuracy: 0.7452 - val_loss: 0.5975 - val_accuracy: 0.7429\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.4928 - accuracy: 0.7476 - val_loss: 0.5980 - val_accuracy: 0.7429\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.4880 - accuracy: 0.7476 - val_loss: 0.5992 - val_accuracy: 0.7429\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.4832 - accuracy: 0.7452 - val_loss: 0.6020 - val_accuracy: 0.7429\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.4792 - accuracy: 0.7548 - val_loss: 0.6029 - val_accuracy: 0.7429\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.4745 - accuracy: 0.7548 - val_loss: 0.6033 - val_accuracy: 0.7429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c65aead60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters from the tuner\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model with the optimal number of epochs and log the results to tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7500\n",
      "Results from test set: loss: 0.5242112874984741 - accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = hypermodel.evaluate(X_test, y_test)\n",
    "print(f'Results from test set: loss: {test_loss} - accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results in tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a48d9d053714610228810daee29d7e6495965b4559be13f38b312ece0e7deaf4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
